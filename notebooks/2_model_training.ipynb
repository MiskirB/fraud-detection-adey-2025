{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-Commerce Dataset:\n",
      "   user_id          signup_time        purchase_time  purchase_value  \\\n",
      "0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
      "1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
      "2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
      "3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
      "4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
      "\n",
      "       device_id source browser sex  age    ip_address  class  \\\n",
      "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0   \n",
      "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0   \n",
      "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1   \n",
      "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0   \n",
      "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0   \n",
      "\n",
      "   time_since_signup  hour_of_day  day_of_week  transaction_count  ip_int  \\\n",
      "0          4506682.0            2            5                  1     NaN   \n",
      "1            17944.0            1            0                  1     NaN   \n",
      "2                1.0           18            3                  1     NaN   \n",
      "3           492085.0           13            0                  1     NaN   \n",
      "4          4361461.0           18            2                  1     NaN   \n",
      "\n",
      "   country  \n",
      "0  Unknown  \n",
      "1  Unknown  \n",
      "2  Unknown  \n",
      "3  Unknown  \n",
      "4  Unknown  \n",
      "\n",
      "Credit Card Dataset:\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Class distribution (E-commerce):\n",
      "class\n",
      "0    0.906354\n",
      "1    0.093646\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution (Credit Card):\n",
      "Class\n",
      "0    0.998333\n",
      "1    0.001667\n",
      "Name: proportion, dtype: float64\n",
      "✅ E-commerce data preprocessing complete.\n",
      "Final shape: (151112, 14)\n",
      "✅ Credit card data preprocessing complete.\n",
      "Final shape: (283726, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Imports and Load Cleaned Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For model training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# For handling imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Visualization settings\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Load cleaned datasets\n",
    "fraud_df = pd.read_csv(\"../data/fraud_data_cleaned.csv\")\n",
    "credit_df = pd.read_csv(\"../data/creditcard_cleaned.csv\")\n",
    "\n",
    "# Show basic info\n",
    "print(\"E-Commerce Dataset:\")\n",
    "print(fraud_df.head())\n",
    "print(\"\\nCredit Card Dataset:\")\n",
    "print(credit_df.head())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution (E-commerce):\")\n",
    "print(fraud_df['class'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution (Credit Card):\")\n",
    "print(credit_df['Class'].value_counts(normalize=True))\n",
    "\n",
    "# Drop non-useful or ID-like columns\n",
    "fraud_df_proc = fraud_df.drop(columns=['user_id', 'device_id', 'ip_address', 'signup_time', 'purchase_time'])\n",
    "\n",
    "# Separate target\n",
    "y_fraud = fraud_df_proc['class']\n",
    "X_fraud = fraud_df_proc.drop(columns=['class'])\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = ['source', 'browser', 'sex', 'country']\n",
    "num_cols = [col for col in X_fraud.columns if col not in cat_cols]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_fraud_encoded = pd.get_dummies(X_fraud, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler_fraud = StandardScaler()\n",
    "X_fraud_encoded[num_cols] = scaler_fraud.fit_transform(X_fraud_encoded[num_cols])\n",
    "\n",
    "print(\"✅ E-commerce data preprocessing complete.\")\n",
    "print(\"Final shape:\", X_fraud_encoded.shape)\n",
    "\n",
    "# -----------------------\n",
    "# Credit Card Preprocessing\n",
    "# -----------------------\n",
    "# Drop Time (optional) and isolate target\n",
    "credit_df_proc = credit_df.drop(columns=['Time'])\n",
    "\n",
    "y_credit = credit_df_proc['Class']\n",
    "X_credit = credit_df_proc.drop(columns=['Class'])\n",
    "\n",
    "# Scale 'Amount'\n",
    "scaler_credit = StandardScaler()\n",
    "X_credit['Amount'] = scaler_credit.fit_transform(X_credit[['Amount']])\n",
    "\n",
    "print(\"✅ Credit card data preprocessing complete.\")\n",
    "print(\"Final shape:\", X_credit.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE (E-commerce): [109568  11321]\n",
      "After SMOTE (E-commerce): [109568 109568]\n",
      "\n",
      "Before SMOTE (Credit Card): [226602    378]\n",
      "After SMOTE (Credit Card): [226602 226602]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train-Test Split + SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# E-commerce dataset\n",
    "# -----------------------------\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(\n",
    "    X_fraud_encoded, y_fraud, test_size=0.2, stratify=y_fraud, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Before SMOTE (E-commerce):\", np.bincount(yf_train))\n",
    "\n",
    "# Fill NaNs before SMOTE\n",
    "Xf_train = Xf_train.fillna(0)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "Xf_train_res, yf_train_res = smote.fit_resample(Xf_train, yf_train)\n",
    "\n",
    "print(\"After SMOTE (E-commerce):\", np.bincount(yf_train_res))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Credit card dataset\n",
    "# -----------------------------\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
    "    X_credit, y_credit, test_size=0.2, stratify=y_credit, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nBefore SMOTE (Credit Card):\", np.bincount(yc_train))\n",
    "\n",
    "# Fill NaNs before SMOTE\n",
    "Xc_train = Xc_train.fillna(0)\n",
    "\n",
    "# Apply SMOTE\n",
    "Xc_train_res, yc_train_res = smote.fit_resample(Xc_train, yc_train)\n",
    "\n",
    "print(\"After SMOTE (Credit Card):\", np.bincount(yc_train_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "os.makedirs(\"../outputs/plots\", exist_ok=True)\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\", dataset_name=\"Dataset\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(f\"\\n🔍 {model_name} on {dataset_name}\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, average='binary'))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # PR AUC\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    print(\"PR AUC:\", pr_auc)\n",
    "\n",
    "    # Plot and save PR Curve\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(recall, precision, label=f'PR AUC = {pr_auc:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve: {model_name} ({dataset_name})')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    fig_path = f\"../outputs/plots/{dataset_name.lower().replace(' ', '_')}_{model_name.lower().replace(' ', '_')}_pr_curve.png\"\n",
    "    plt.savefig(fig_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load and prepare dataset\n",
    "fraud_df = pd.read_csv(\"../data/fraud_data_cleaned.csv\")\n",
    "fraud_df_proc = fraud_df.drop(columns=['user_id', 'device_id', 'ip_address', 'signup_time', 'purchase_time'])\n",
    "y_fraud = fraud_df_proc['class']\n",
    "X_fraud = fraud_df_proc.drop(columns=['class'])\n",
    "\n",
    "# Define columns\n",
    "cat_cols = ['source', 'browser', 'sex', 'country']\n",
    "num_cols = [col for col in X_fraud.columns if col not in cat_cols]\n",
    "\n",
    "# Handle NaNs and Infs\n",
    "X_fraud[num_cols] = X_fraud[num_cols].replace([np.inf, -np.inf], np.nan)\n",
    "X_fraud[num_cols] = X_fraud[num_cols].fillna(X_fraud[num_cols].median())\n",
    "\n",
    "# Encode categoricals\n",
    "X_fraud_encoded = pd.get_dummies(X_fraud, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Scale numeric\n",
    "scaler = StandardScaler()\n",
    "X_fraud_encoded[num_cols] = scaler.fit_transform(X_fraud_encoded[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE (E-commerce): [109568  11321]\n",
      "After SMOTE (E-commerce): [109568 109568]\n"
     ]
    }
   ],
   "source": [
    "# 3. Split Data and Apply SMOTE\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(\n",
    "    X_fraud_encoded, y_fraud, test_size=0.2, stratify=y_fraud, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Before SMOTE (E-commerce):\", np.bincount(yf_train))\n",
    "\n",
    "# Fill NaNs before SMOTE\n",
    "Xf_train = Xf_train.fillna(0)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "Xf_train_res, yf_train_res = smote.fit_resample(Xf_train, yf_train)\n",
    "\n",
    "print(\"After SMOTE (E-commerce):\", np.bincount(yf_train_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   purchase_value       age  time_since_signup  hour_of_day  day_of_week  \\\n",
      "0        2.132034 -0.480488           0.936929    -1.232789     1.489476   \n",
      "1        0.167258 -0.828608           1.607740     1.226541     0.492565   \n",
      "2       -0.705975 -1.060689          -0.099615    -1.522122    -0.005891   \n",
      "3        3.005268  0.099713           1.491283    -0.075457     1.489476   \n",
      "4       -0.596821 -0.016327          -0.485322     0.647875    -0.504347   \n",
      "\n",
      "   transaction_count  ip_int  source_Direct  source_SEO  browser_FireFox  \\\n",
      "0                0.0     0.0           True       False            False   \n",
      "1                0.0     0.0          False        True            False   \n",
      "2                0.0     0.0          False       False            False   \n",
      "3                0.0     0.0          False        True            False   \n",
      "4                0.0     0.0          False        True            False   \n",
      "\n",
      "   browser_IE  browser_Opera  browser_Safari  sex_M  \n",
      "0        True          False           False  False  \n",
      "1       False          False            True   True  \n",
      "2       False          False           False   True  \n",
      "3       False          False           False  False  \n",
      "4        True          False           False   True  \n",
      "class\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "fraud_df = pd.read_csv(\"../data/fraud_data_cleaned.csv\")\n",
    "fraud_df_proc = fraud_df.drop(columns=['user_id', 'device_id', 'ip_address', 'signup_time', 'purchase_time'])\n",
    "\n",
    "y_fraud = fraud_df_proc['class']\n",
    "X_fraud = fraud_df_proc.drop(columns=['class'])\n",
    "\n",
    "# Encode and scale\n",
    "X_fraud = pd.get_dummies(X_fraud, columns=['source', 'browser', 'sex', 'country'], drop_first=True)\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['purchase_value', 'age', 'time_since_signup', 'hour_of_day', 'day_of_week', 'transaction_count', 'ip_int']\n",
    "X_fraud[num_cols] = scaler.fit_transform(X_fraud[num_cols])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fraud.fillna(0), y_fraud, test_size=0.2, stratify=y_fraud)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# View sample\n",
    "print(X_train_res.head())\n",
    "print(y_train_res.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/jerus/Desktop/KAIM/fraud-detection-adey-2025/venv/lib/python3.13/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: [109568  11321]\n",
      "After SMOTE: [109568 109568]\n",
      "\n",
      "🔍 Random Forest on E-commerce\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9535    0.9937    0.9732     27393\n",
      "           1     0.8968    0.5314    0.6674      2830\n",
      "\n",
      "    accuracy                         0.9504     30223\n",
      "   macro avg     0.9252    0.7626    0.8203     30223\n",
      "weighted avg     0.9482    0.9504    0.9446     30223\n",
      "\n",
      "F1 Score: 0.6674062569336587\n",
      "Confusion Matrix:\n",
      " [[27220   173]\n",
      " [ 1326  1504]]\n",
      "PR AUC: 0.6224860000146311\n",
      "✅ Saved to ../outputs/plots/e-commerce_random_forest_pr_curve_20250802_152354.png\n",
      "\n",
      "🔍 Logistic Regression on E-commerce\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9530    0.6430    0.7679     27393\n",
      "           1     0.1671    0.6933    0.2693      2830\n",
      "\n",
      "    accuracy                         0.6478     30223\n",
      "   macro avg     0.5601    0.6682    0.5186     30223\n",
      "weighted avg     0.8794    0.6478    0.7213     30223\n",
      "\n",
      "F1 Score: 0.26932052161976666\n",
      "Confusion Matrix:\n",
      " [[17615  9778]\n",
      " [  868  1962]]\n",
      "PR AUC: 0.4076297077284232\n",
      "✅ Saved to ../outputs/plots/e-commerce_logistic_regression_pr_curve_20250802_152355.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fraud Classification Evaluation - Self-Contained Notebook\n",
    "\n",
    "# 1. Imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 2. Setup\n",
    "sns.set(style='whitegrid')\n",
    "os.makedirs(\"../outputs/plots\", exist_ok=True)\n",
    "\n",
    "# 3. Load Preprocessed E-commerce Dataset\n",
    "fraud_df = pd.read_csv(\"../data/fraud_data_cleaned.csv\")\n",
    "fraud_df_proc = fraud_df.drop(columns=['user_id', 'device_id', 'ip_address', 'signup_time', 'purchase_time'])\n",
    "y_fraud = fraud_df_proc['class']\n",
    "X_fraud = fraud_df_proc.drop(columns=['class'])\n",
    "\n",
    "cat_cols = ['source', 'browser', 'sex', 'country']\n",
    "num_cols = [col for col in X_fraud.columns if col not in cat_cols]\n",
    "\n",
    "X_fraud_encoded = pd.get_dummies(X_fraud, columns=cat_cols, drop_first=True)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_fraud_encoded[num_cols] = scaler.fit_transform(X_fraud_encoded[num_cols])\n",
    "X_fraud_encoded = X_fraud_encoded.fillna(0)\n",
    "\n",
    "# 4. Train-Test Split and SMOTE\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(X_fraud_encoded, y_fraud, test_size=0.2, stratify=y_fraud, random_state=42)\n",
    "print(\"Before SMOTE:\", np.bincount(yf_train))\n",
    "smote = SMOTE(random_state=42)\n",
    "Xf_train_res, yf_train_res = smote.fit_resample(Xf_train, yf_train)\n",
    "print(\"After SMOTE:\", np.bincount(yf_train_res))\n",
    "\n",
    "# 5. Define Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\", dataset_name=\"Dataset\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"\\n🔍 {model_name} on {dataset_name}\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, average='binary'))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    print(\"PR AUC:\", pr_auc)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(recall, precision, label=f'PR AUC = {pr_auc:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve: {model_name} ({dataset_name})')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{dataset_name.lower().replace(' ', '_')}_{model_name.lower().replace(' ', '_')}_pr_curve_{timestamp}.png\"\n",
    "    filepath = os.path.join(\"../outputs/plots\", filename)\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "    print(f\"✅ Saved to {filepath}\")\n",
    "\n",
    "# 6. Train & Evaluate Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(Xf_train_res, yf_train_res)\n",
    "evaluate_model(rf_model, Xf_test, yf_test, \"Random Forest\", \"E-commerce\")\n",
    "\n",
    "# 7. Train & Evaluate Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_model.fit(Xf_train_res, yf_train_res)\n",
    "evaluate_model(log_model, Xf_test, yf_test, \"Logistic Regression\", \"E-commerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SHAP summary bar saved at: ../outputs/plots/shap_summary_bar_ecommerce.png\n",
      "✅ SHAP beeswarm plot saved at: ../outputs/plots/shap_beeswarm_ecommerce.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Train Random Forest (if not done already)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_fraud = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_fraud.fit(Xf_train_res, yf_train_res)\n",
    "\n",
    "# 2. SHAP Interpretability\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Ensure plot directory exists\n",
    "os.makedirs(\"../outputs/plots\", exist_ok=True)\n",
    "\n",
    "# Initialize SHAP TreeExplainer\n",
    "explainer = shap.TreeExplainer(rf_fraud)\n",
    "\n",
    "# Sample a subset of the test set to speed up computation\n",
    "Xf_test_sample = Xf_test.sample(n=300, random_state=42)\n",
    "\n",
    "# Compute SHAP values for the fraud class (class 1)\n",
    "shap_values = explainer.shap_values(Xf_test_sample)\n",
    "\n",
    "# 3. SHAP Summary Bar Plot\n",
    "plt.figure()\n",
    "# Check if shap_values is a list (as in classifiers)\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values_class1 = shap_values[1]  # For binary classifiers: class 1 (fraud)\n",
    "else:\n",
    "    shap_values_class1 = shap_values  # For regression or single-output\n",
    "\n",
    "# Align dimensions by converting DataFrame (some dtypes like bool can cause issues)\n",
    "X_sample_fixed = Xf_test_sample.astype(float)\n",
    "\n",
    "# SHAP Summary Bar Plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values_class1, X_sample_fixed, plot_type='bar', show=False)\n",
    "bar_path = \"../outputs/plots/shap_summary_bar_ecommerce.png\"\n",
    "plt.savefig(bar_path)\n",
    "plt.close()\n",
    "print(f\"✅ SHAP summary bar saved at: {bar_path}\")\n",
    "\n",
    "# SHAP Beeswarm Plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values_class1, X_sample_fixed, show=False)\n",
    "bee_path = \"../outputs/plots/shap_beeswarm_ecommerce.png\"\n",
    "plt.savefig(bee_path)\n",
    "plt.close()\n",
    "print(f\"✅ SHAP beeswarm plot saved at: {bee_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_fraud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33m../outputs/plots\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Initialize explainer for Random Forest\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m explainer = shap.TreeExplainer(\u001b[43mrf_fraud\u001b[49m)\n\u001b[32m      9\u001b[39m shap_values = explainer.shap_values(Xf_test)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Get indices for fraud and non-fraud cases\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'rf_fraud' is not defined"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"../outputs/plots\", exist_ok=True)\n",
    "\n",
    "# Initialize explainer for Random Forest\n",
    "explainer = shap.TreeExplainer(rf_fraud)\n",
    "shap_values = explainer.shap_values(Xf_test)\n",
    "\n",
    "# Get indices for fraud and non-fraud cases\n",
    "fraud_idx = yf_test[yf_test == 1].index[0]\n",
    "nonfraud_idx = yf_test[yf_test == 0].index[0]\n",
    "\n",
    "# Select samples\n",
    "fraud_sample = Xf_test.loc[[fraud_idx]]\n",
    "nonfraud_sample = Xf_test.loc[[nonfraud_idx]]\n",
    "\n",
    "# Force Plot - Fraud\n",
    "fraud_force_plot = shap.force_plot(\n",
    "    explainer.expected_value[1],\n",
    "    shap_values[1][Xf_test.index.get_loc(fraud_idx)],\n",
    "    fraud_sample,\n",
    "    matplotlib=False\n",
    ")\n",
    "shap.save_html(\"../outputs/plots/shap_force_fraud.html\", fraud_force_plot)\n",
    "print(\"✅ Fraud force plot saved: shap_force_fraud.html\")\n",
    "\n",
    "# Force Plot - Non-Fraud\n",
    "nonfraud_force_plot = shap.force_plot(\n",
    "    explainer.expected_value[1],\n",
    "    shap_values[1][Xf_test.index.get_loc(nonfraud_idx)],\n",
    "    nonfraud_sample,\n",
    "    matplotlib=False\n",
    ")\n",
    "shap.save_html(\"../outputs/plots/shap_force_nonfraud.html\", nonfraud_force_plot)\n",
    "print(\"✅ Non-fraud force plot saved: shap_force_nonfraud.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
